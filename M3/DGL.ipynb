{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a0cb309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>weight</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.640525</td>\n",
       "      <td>1300</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15.202562</td>\n",
       "      <td>1300</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.457279</td>\n",
       "      <td>1300</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>19.127800</td>\n",
       "      <td>1300</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16.647304</td>\n",
       "      <td>1300</td>\n",
       "      <td>3167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802854</th>\n",
       "      <td>0</td>\n",
       "      <td>19.403629</td>\n",
       "      <td>469</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802855</th>\n",
       "      <td>0</td>\n",
       "      <td>12.932615</td>\n",
       "      <td>2622</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802856</th>\n",
       "      <td>0</td>\n",
       "      <td>7.594553</td>\n",
       "      <td>2622</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802857</th>\n",
       "      <td>0</td>\n",
       "      <td>17.301979</td>\n",
       "      <td>2523</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802858</th>\n",
       "      <td>0</td>\n",
       "      <td>19.447633</td>\n",
       "      <td>814</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>802859 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type     weight  source  target\n",
       "0          0  10.640525    1300     742\n",
       "1          0  15.202562    1300     291\n",
       "2          0   4.457279    1300    1245\n",
       "3          0  19.127800    1300     412\n",
       "4          0  16.647304    1300    3167\n",
       "...      ...        ...     ...     ...\n",
       "802854     0  19.403629     469    1464\n",
       "802855     0  12.932615    2622     814\n",
       "802856     0   7.594553    2622     717\n",
       "802857     0  17.301979    2523     814\n",
       "802858     0  19.447633     814     717\n",
       "\n",
       "[802859 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import collections as col\n",
    "from IPython.display import IFrame\n",
    "from geopy import distance\n",
    "import statistics\n",
    "import math\n",
    "import dgl\n",
    "\n",
    "# import geopy\n",
    "# from geopy import distance\n",
    "from geolib import geohash as gh\n",
    "import json\n",
    "nodes_enc = pd.read_csv('nodes_encoded_11_21', sep='\\t')\n",
    "er = pd.read_csv('edge_enc_11_21', sep='\\t')\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b01ebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3389, num_edges=806248,\n",
      "      ndata_schemes={'feat': Scheme(shape=(4,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'edgetype': Scheme(shape=(), dtype=torch.int64), 'distance': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "lb_make = LabelEncoder()\n",
    "# Load and encode node features\n",
    "\n",
    "er = pd.read_csv('edges_remove_11_20', sep='\\t')\n",
    "nodes_cpy = pd.read_csv('nodes_cpy',sep='\\t')\n",
    "\n",
    "src = np.asarray(er['source'].to_numpy()).astype(int)\n",
    "dst = np.asarray(er['target'].to_numpy()).astype(int)\n",
    "\n",
    "# # # Create a DGL graph from a pair of numpy arrays\n",
    "# # src_tensor = tf.convert_to_tensor(src)\n",
    "g = dgl.graph((src, dst))\n",
    "\n",
    "# edges_enc = pd.DataFrame()\n",
    "nodes_enc = pd.DataFrame()\n",
    "nodes_enc['id'] = nodes_cpy['id']\n",
    "nodes_enc['id_enc'] = lb_make.fit_transform(nodes_cpy['id'])\n",
    "nodes_enc['geohash'] = lb_make.fit_transform(nodes_cpy['geohash'])\n",
    "nodes_enc['category'] = lb_make.fit_transform(nodes_cpy['filtered_cat'])\n",
    "nodes_enc['stars'] = lb_make.fit_transform(nodes_cpy['stars'])\n",
    "nodes_enc['lat'] = nodes_cpy['latitude']\n",
    "nodes_enc['lon'] = nodes_cpy['longitude']\n",
    "\n",
    "\n",
    "# edges_enc['type'] = lb_make.fit_transform(edges['t'])\n",
    "geohash = torch.tensor(nodes_enc['geohash'].to_numpy()).long()\n",
    "category = torch.tensor(nodes_enc['category'].to_numpy()).long()\n",
    "lat = torch.tensor(nodes_cpy['latitude'].to_numpy()).long()\n",
    "lon =  torch.tensor(nodes_cpy['longitude'].to_numpy()).long()\n",
    "stars =  torch.tensor(nodes_cpy['stars'].to_numpy()).long()\n",
    "tensor_list =[geohash,lat,lon,category]\n",
    "stacked_tensor = torch.stack(tensor_list,dim=1)\n",
    "g.ndata['feat'] = stacked_tensor\n",
    "g.ndata['label'] = stars\n",
    "# print(stacked_tensor)\n",
    "# Add node attributes to graph\n",
    "# g.ndata['geohash'] = geohash\n",
    "# g.ndata['category'] = category\n",
    "# g.ndata['stars'] = stars\n",
    "# g.ndata['lat'] = lat\n",
    "# g.ndata['lon'] = lon\n",
    "\n",
    "edges_enc = pd.DataFrame()\n",
    "edges_enc['type'] = lb_make.fit_transform(er['edgetype'])\n",
    "edges_enc['weight'] = er['weight']\n",
    "edgetype = torch.tensor(edges_enc['type'].to_numpy()).long()\n",
    "distance = torch.tensor(er['weight'].to_numpy()).long()\n",
    "\n",
    "# Add edge attributes\n",
    "g.edata['edgetype'] = edgetype\n",
    "g.edata['distance'] = distance\n",
    "g = dgl.add_self_loop(g)\n",
    "# g = dgl.to_bidirected(g,True)\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12fd31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct a two-layer GNN model\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "from dgl.data import DGLDataset\n",
    "import dgl.function as dglfn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "def process_graph(graph):\n",
    "    # If your dataset is a node classification dataset, you will need to assign\n",
    "    # masks indicating whether a node belongs to training, validation, and test set.\n",
    "    n_nodes = graph.num_nodes()\n",
    "    n_train = int(n_nodes * 0.8)\n",
    "    n_val = int(n_nodes * 0.1)\n",
    "    train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "    pop = [*range(n_nodes)]\n",
    "    train_idx = random.sample(pop,n_train)\n",
    "    for train_i in train_idx:\n",
    "        pop.remove(train_i)\n",
    "    val_idx = random.sample(pop,n_val)\n",
    "    for val_i in val_idx:\n",
    "        pop.remove(val_i)\n",
    "    test_idx = pop\n",
    "    # train_mask[:n_train] = True\n",
    "    # val_mask[n_train:n_train + n_val] = True\n",
    "    # test_mask[n_train + n_val:] = True\n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[val_idx] = True\n",
    "    test_mask[test_idx] = True\n",
    "    graph.ndata['train_mask'] = train_mask\n",
    "    graph.ndata['val_mask'] = val_mask\n",
    "    graph.ndata['test_mask'] = test_mask\n",
    "    return graph\n",
    "\n",
    "\n",
    "# class GCN(nn.Module):\n",
    "#     def __init__(self, in_feats, h_feats, num_classes):\n",
    "#         super(GCN, self).__init__()\n",
    "#         self.conv1 = GraphConv(in_feats, h_feats)\n",
    "#         self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "#     def forward(self, g, in_feat):\n",
    "#         h = self.conv1(g, in_feat)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv2(g, h)\n",
    "#         return h  \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = dglnn.GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = dglnn.GraphConv(in_feats, h_feats)\n",
    "        self.conv3 = dglnn.GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "#         h = F.softmax(h)\n",
    "        h = self.conv3(g, h)\n",
    "        return h\n",
    "\n",
    "class GATConv(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GATConv, self).__init__()\n",
    "        self.conv1 = dglnn.GATConv(n_feats=in_feats, out_feats=h_feats, num_heads=2)\n",
    "        self.conv2 = dglnn.GATConv(in_feats=h_feats,  out_feats=num_classes, num_heads=2)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h    \n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=h_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=h_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h\n",
    "    \n",
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "    \n",
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "        # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "344da48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 53.360, val acc: 0.024 (best 0.024), test acc: 0.006 (best 0.006)\n",
      "In epoch 5, loss: 21.426, val acc: 0.068 (best 0.068), test acc: 0.065 (best 0.065)\n",
      "In epoch 10, loss: 10.211, val acc: 0.266 (best 0.266), test acc: 0.276 (best 0.276)\n",
      "In epoch 15, loss: 1.935, val acc: 0.464 (best 0.464), test acc: 0.500 (best 0.500)\n",
      "In epoch 20, loss: 5.013, val acc: 0.503 (best 0.503), test acc: 0.521 (best 0.521)\n",
      "In epoch 25, loss: 3.040, val acc: 0.503 (best 0.503), test acc: 0.521 (best 0.521)\n",
      "In epoch 30, loss: 2.877, val acc: 0.284 (best 0.503), test acc: 0.276 (best 0.521)\n",
      "In epoch 35, loss: 1.882, val acc: 0.506 (best 0.506), test acc: 0.521 (best 0.521)\n",
      "In epoch 40, loss: 1.742, val acc: 0.500 (best 0.506), test acc: 0.515 (best 0.521)\n",
      "In epoch 45, loss: 1.657, val acc: 0.299 (best 0.506), test acc: 0.288 (best 0.521)\n",
      "In epoch 50, loss: 1.602, val acc: 0.503 (best 0.506), test acc: 0.518 (best 0.521)\n",
      "In epoch 55, loss: 1.480, val acc: 0.305 (best 0.506), test acc: 0.291 (best 0.521)\n",
      "In epoch 60, loss: 1.433, val acc: 0.491 (best 0.506), test acc: 0.512 (best 0.521)\n",
      "In epoch 65, loss: 1.394, val acc: 0.340 (best 0.506), test acc: 0.344 (best 0.521)\n",
      "In epoch 70, loss: 1.386, val acc: 0.497 (best 0.506), test acc: 0.512 (best 0.521)\n",
      "In epoch 75, loss: 1.374, val acc: 0.346 (best 0.506), test acc: 0.376 (best 0.521)\n",
      "In epoch 80, loss: 1.365, val acc: 0.494 (best 0.506), test acc: 0.526 (best 0.521)\n",
      "In epoch 85, loss: 1.357, val acc: 0.367 (best 0.506), test acc: 0.397 (best 0.521)\n",
      "In epoch 90, loss: 1.350, val acc: 0.485 (best 0.506), test acc: 0.521 (best 0.521)\n",
      "In epoch 95, loss: 1.345, val acc: 0.420 (best 0.506), test acc: 0.485 (best 0.521)\n"
     ]
    }
   ],
   "source": [
    "## GCN\n",
    "\n",
    "graph = process_graph(g)\n",
    "\n",
    "node_features = graph.ndata['feat']\n",
    "node_labels = graph.ndata['label']\n",
    "train_mask = graph.ndata['train_mask']\n",
    "valid_mask = graph.ndata['val_mask']\n",
    "test_mask = graph.ndata['test_mask']\n",
    "# n_features = node_features.shape[1]\n",
    "graph.ndata['label'] = graph.ndata['label'].type(torch.LongTensor)\n",
    "\n",
    "model = GCN(graph.ndata['feat'].shape[1], 16, len(set(nodes_enc['stars'])))\n",
    "train(graph, model)\n",
    "# print(graph.ndata['feat'].shape[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
